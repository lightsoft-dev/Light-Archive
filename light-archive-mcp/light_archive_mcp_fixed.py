#!/usr/bin/env python3
"""
Light Archive MCP Server (v1.0.7)

ì‹¤ì œ Light Archive í”„ë¡œì íŠ¸ì˜ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •ëœ ë²„ì „ì…ë‹ˆë‹¤.
í…Œì´ë¸”: archive_items (ë‹¨ì¼ í…Œì´ë¸”, tagsì™€ technologiesëŠ” ë°°ì—´ í•„ë“œ)

v1.0.7 ë³€ê²½ì‚¬í•­:
- AI ê´€ë ¨ ë„êµ¬ ì œê±° (generate_draft, generate_summary, suggest_tags)
- content í•„ë“œë¥¼ HTML í˜•ì‹ìœ¼ë¡œ ëª…í™•íˆ ì§€ì •
- ë‚ ì§œ ìë™ ìƒì„± ê°œì„  (created_at, updated_at, published_at)
- ì‘ë‹µ ë©”ì‹œì§€ë¥¼ HTML êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€ê²½
"""

import os
import json
import asyncio
import time
import random
import string
import io
from typing import Optional, List, Dict, Any
from enum import Enum
from datetime import datetime
from pathlib import Path

# Third-party imports
from dotenv import load_dotenv
from pydantic import BaseModel, Field, ConfigDict
from mcp.server.fastmcp import FastMCP
from supabase import create_client, Client
from openai import AsyncOpenAI
from PIL import Image as PILImage

# Load environment variables
load_dotenv()

# ============================================================================
# INITIALIZATION
# ============================================================================

# Initialize MCP server
mcp = FastMCP("light_archive_mcp")

# Initialize Supabase client
SUPABASE_URL = os.getenv("NEXT_PUBLIC_SUPABASE_URL", "")
SUPABASE_ANON_KEY = os.getenv("NEXT_PUBLIC_SUPABASE_ANON_KEY", "")

if not SUPABASE_URL or not SUPABASE_ANON_KEY:
    print("Warning: Supabase credentials not found")
    supabase: Optional[Client] = None
else:
    try:
        supabase: Client = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)
    except Exception as e:
        print(f"Warning: Failed to initialize Supabase: {e}")
        supabase = None

# Initialize OpenAI client
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

if not OPENAI_API_KEY:
    print("Warning: OpenAI API key not found")
    openai_client: Optional[AsyncOpenAI] = None
else:
    try:
        openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
    except Exception as e:
        print(f"Warning: Failed to initialize OpenAI: {e}")
        openai_client = None

# ============================================================================
# CONSTANTS
# ============================================================================

CHARACTER_LIMIT = 25000
DEFAULT_LIMIT = 20
MAX_RETRIES = 3

# ============================================================================
# ENUMS
# ============================================================================

class ArchiveCategory(str, Enum):
    """ì•„ì¹´ì´ë¸Œ ì¹´í…Œê³ ë¦¬"""
    TECH = "ê¸°ìˆ "
    PROJECT = "í”„ë¡œì íŠ¸"
    RESEARCH = "ë¦¬ì„œì¹˜"
    NEWS = "ë‰´ìŠ¤"


class ArchiveStatus(str, Enum):
    """ì•„ì¹´ì´ë¸Œ ìƒíƒœ"""
    DRAFT = "draft"
    PUBLISHED = "published"
    ARCHIVED = "archived"


class ResponseFormat(str, Enum):
    """ì‘ë‹µ í¬ë§·"""
    MARKDOWN = "markdown"
    JSON = "json"


# ============================================================================
# PYDANTIC MODELS
# ============================================================================

class SearchArchivesInput(BaseModel):
    """ì•„ì¹´ì´ë¸Œ ê²€ìƒ‰ ì…ë ¥"""
    model_config = ConfigDict(str_strip_whitespace=True)

    query: str = Field(..., min_length=2, max_length=200,
                      description="ê²€ìƒ‰ì–´ (ì œëª©, ì„¤ëª…, ë‚´ìš©ì—ì„œ ê²€ìƒ‰)")
    category: Optional[ArchiveCategory] = Field(None, description="ì¹´í…Œê³ ë¦¬ í•„í„°")
    limit: int = Field(DEFAULT_LIMIT, ge=1, le=100)
    offset: int = Field(0, ge=0)
    response_format: ResponseFormat = Field(ResponseFormat.MARKDOWN)


class GetArchiveInput(BaseModel):
    """ì•„ì¹´ì´ë¸Œ ì¡°íšŒ ì…ë ¥"""
    model_config = ConfigDict(str_strip_whitespace=True)

    archive_id: str = Field(..., description="ì•„ì¹´ì´ë¸Œ ID")
    response_format: ResponseFormat = Field(ResponseFormat.MARKDOWN)


class CreateArchiveInput(BaseModel):
    """
    ì•„ì¹´ì´ë¸Œ ìƒì„± ì…ë ¥

    **ì¤‘ìš”**: contentëŠ” ë°˜ë“œì‹œ HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    - êµ¬ì¡°í™”ëœ HTML íƒœê·¸ ì‚¬ìš© (h1, h2, h3, p, ul, ol, code, pre ë“±)
    - ë§ˆí¬ë‹¤ìš´ì´ ì•„ë‹Œ HTMLë¡œ ì‘ì„±
    - ì˜ˆ: <h2>ì„¹ì…˜ ì œëª©</h2><p>ë‚´ìš©...</p>
    """
    model_config = ConfigDict(str_strip_whitespace=True)

    title: str = Field(..., min_length=3, max_length=200, description="ì œëª©")
    content: str = Field(
        ...,
        min_length=10,
        description="ë³¸ë¬¸ ë‚´ìš© (ë°˜ë“œì‹œ HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„± - <h2>, <p>, <ul> ë“± ì‚¬ìš©)"
    )
    category: ArchiveCategory = Field(..., description="ì¹´í…Œê³ ë¦¬ (ê¸°ìˆ /í”„ë¡œì íŠ¸/ë¦¬ì„œì¹˜/ë‰´ìŠ¤)")
    description: str = Field(..., min_length=10, max_length=500, description="ì„¤ëª… (í•„ìˆ˜, 4-5ì¤„ ìš”ì•½)")
    tags: List[str] = Field(..., min_items=1, max_items=10, description="íƒœê·¸ ë°°ì—´")
    technologies: List[str] = Field(..., min_items=1, max_items=20, description="ê¸°ìˆ  ìŠ¤íƒ ë°°ì—´")
    sub_category: Optional[str] = Field(None, max_length=100, description="ì„œë¸Œ ì¹´í…Œê³ ë¦¬/ë¶„ì•¼")
    excerpt: Optional[str] = Field(None, max_length=500, description="ìš”ì•½ë¬¸ (ì„ íƒ)")
    author: Optional[str] = Field(None, max_length=100, description="ì‘ì„±ì")
    difficulty: Optional[str] = Field(None, description="ë‚œì´ë„")
    thumbnail_url: Optional[str] = Field(None, description="ì¸ë„¤ì¼ URL")


class UpdateArchiveInput(BaseModel):
    """ì•„ì¹´ì´ë¸Œ ìˆ˜ì • ì…ë ¥"""
    model_config = ConfigDict(str_strip_whitespace=True)

    archive_id: str = Field(..., description="ì•„ì¹´ì´ë¸Œ ID")
    title: Optional[str] = Field(None, min_length=3, max_length=200)
    content: Optional[str] = Field(None, min_length=10)
    description: Optional[str] = Field(None, min_length=10, max_length=500)
    excerpt: Optional[str] = Field(None, max_length=500)
    category: Optional[ArchiveCategory] = Field(None)
    sub_category: Optional[str] = Field(None, max_length=100)
    tags: Optional[List[str]] = Field(None, max_items=10)
    technologies: Optional[List[str]] = Field(None, max_items=20)
    difficulty: Optional[str] = Field(None)


class GenerateDraftInput(BaseModel):
    """AI ì´ˆì•ˆ ìƒì„± ì…ë ¥"""
    model_config = ConfigDict(str_strip_whitespace=True)

    category: ArchiveCategory
    sub_category: str = Field(..., min_length=3, max_length=100, description="ì„œë¸Œ ì¹´í…Œê³ ë¦¬/ë¶„ì•¼")
    topic: str = Field(..., min_length=5, max_length=200, description="ì£¼ì œ")
    technologies: Optional[List[str]] = Field(None, max_items=10)


class GenerateSummaryInput(BaseModel):
    """AI ìš”ì•½ ìƒì„± ì…ë ¥"""
    model_config = ConfigDict(str_strip_whitespace=True)

    content: str = Field(..., min_length=100, description="ìš”ì•½í•  ë‚´ìš©")
    target_length: int = Field(100, ge=80, le=120)


class SuggestTagsInput(BaseModel):
    """AI íƒœê·¸ ì¶”ì²œ ì…ë ¥"""
    model_config = ConfigDict(str_strip_whitespace=True)

    title: str = Field(..., min_length=3, max_length=200)
    content: str = Field(..., min_length=50)
    category: ArchiveCategory
    max_suggestions: int = Field(10, ge=5, le=15)


class FindRelatedInput(BaseModel):
    """ìœ ì‚¬ ì•„ì¹´ì´ë¸Œ ì°¾ê¸° ì…ë ¥"""
    model_config = ConfigDict(str_strip_whitespace=True)

    archive_id: str
    limit: int = Field(4, ge=1, le=10)
    response_format: ResponseFormat = Field(ResponseFormat.MARKDOWN)


class ListArchivesInput(BaseModel):
    """ì•„ì¹´ì´ë¸Œ ëª©ë¡ ì¡°íšŒ ì…ë ¥"""
    model_config = ConfigDict(str_strip_whitespace=True)

    category: Optional[ArchiveCategory] = Field(None)
    status: Optional[ArchiveStatus] = Field(None)
    limit: int = Field(DEFAULT_LIMIT, ge=1, le=100)
    offset: int = Field(0, ge=0)
    response_format: ResponseFormat = Field(ResponseFormat.MARKDOWN)


class UploadImageInput(BaseModel):
    """ì´ë¯¸ì§€ ì—…ë¡œë“œ ì…ë ¥ - íŒŒì¼ ê²½ë¡œë§Œ ë°›ìŒ"""
    model_config = ConfigDict(str_strip_whitespace=True)

    image_path: str = Field(
        ...,
        description="Path to image file (e.g., /mnt/user-data/uploads/image.png)"
    )
    filename: Optional[str] = Field(None, description="íŒŒì¼ëª… (ì„ íƒ, ì—†ìœ¼ë©´ ìë™ ìƒì„±)")


class AnalyzeImageInput(BaseModel):
    """ì´ë¯¸ì§€ ë¶„ì„ ì…ë ¥ - íŒŒì¼ ê²½ë¡œë§Œ ë°›ìŒ"""
    model_config = ConfigDict(str_strip_whitespace=True)

    image_path: str = Field(
        ...,
        description="Path to image file (e.g., /mnt/user-data/uploads/image.png)"
    )
    prompt: Optional[str] = Field(
        "ì´ ì´ë¯¸ì§€ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì£¼ìš” ìš”ì†Œ, ìƒ‰ìƒ, êµ¬ì„±, ê·¸ë¦¬ê³  ì „ë°˜ì ì¸ ë¶„ìœ„ê¸°ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.",
        description="ì´ë¯¸ì§€ ë¶„ì„ í”„ë¡¬í”„íŠ¸"
    )


class GenerateDraftWithImagesInput(BaseModel):
    """ì´ë¯¸ì§€ ê¸°ë°˜ ì´ˆì•ˆ ìƒì„± ì…ë ¥ - íŒŒì¼ ê²½ë¡œë§Œ ë°›ìŒ"""
    model_config = ConfigDict(str_strip_whitespace=True)

    image_paths: List[str] = Field(
        ...,
        min_length=1,
        max_length=5,
        description="Paths to image files (max 5 images, e.g., ['/mnt/user-data/uploads/img1.png'])"
    )
    title: str = Field(..., min_length=3, max_length=200, description="ì•„ì¹´ì´ë¸Œ ì œëª©")
    category: ArchiveCategory = Field(..., description="ì¹´í…Œê³ ë¦¬")
    context: Optional[str] = Field(None, description="ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (í”„ë¡œì íŠ¸ ì„¤ëª…, ê¸°ìˆ  ìŠ¤íƒ ë“±)")


# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def _check_supabase() -> None:
    if supabase is None:
        raise RuntimeError("Supabase not initialized. Please check environment variables.")


def _check_openai() -> None:
    if openai_client is None:
        raise RuntimeError("OpenAI not initialized. Please check OPENAI_API_KEY.")


def _generate_archive_id() -> str:
    """
    ì•„ì¹´ì´ë¸Œ ID ìƒì„± (Next.js ì•±ê³¼ ë™ì¼í•œ íŒ¨í„´)
    íŒ¨í„´: {timestamp}-{random_string}
    ì˜ˆ: 1761901131544-a2mnqr
    """
    timestamp = str(int(time.time() * 1000))  # ë°€ë¦¬ì´ˆ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„

    # ëœë¤ ë¬¸ìì—´ ìƒì„± (6ìë¦¬, ì†Œë¬¸ì+ìˆ«ì)
    # JavaScriptì˜ Math.random().toString(36).substring(7)ê³¼ ë™ì¼í•œ ê²°ê³¼
    random_chars = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))

    return f"{timestamp}-{random_chars}"


async def _upload_image_to_storage(
    image_path: str,
    filename: Optional[str] = None
) -> str:
    """
    íŒŒì¼ ê²½ë¡œì—ì„œ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ì½ì–´ì„œ Supabase Storageì— ì—…ë¡œë“œ
    Base64 ì¸ì½”ë”© ì—†ì´ ë°”ì´ë„ˆë¦¬ë¡œ ì§ì ‘ ì²˜ë¦¬

    Args:
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (e.g., /mnt/user-data/uploads/image.png)
        filename: íŒŒì¼ëª… (ì—†ìœ¼ë©´ ìë™ ìƒì„±)

    Returns:
        Public URL
    """
    _check_supabase()

    try:
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

        # PILë¡œ ì´ë¯¸ì§€ ì—´ê¸° (ê²€ì¦ + í¬ë§· í™•ì¸)
        with PILImage.open(image_path) as img:
            # ì´ë¯¸ì§€ í¬ë§· í™•ì¸
            img_format = img.format.lower() if img.format else 'png'

            # ë°”ì´ë„ˆë¦¬ë¡œ ë³€í™˜
            buffer = io.BytesIO()
            img.save(buffer, format=img_format.upper())
            image_data = buffer.getvalue()

        # íŒŒì¼ëª… ìƒì„± (Next.js ì•±ê³¼ ë™ì¼í•œ íŒ¨í„´)
        if not filename:
            filename = _generate_archive_id()

        filename_with_ext = f"{filename}.{img_format}"
        file_path = f"archive-images/{filename_with_ext}"

        # Supabase Storageì— ì—…ë¡œë“œ
        response = supabase.storage.from_("thumbnails").upload(
            file_path,
            image_data,
            {
                "content-type": f"image/{img_format}",
                "cacheControl": "3600",
                "upsert": "false"
            }
        )

        # ì—…ë¡œë“œ ì‹¤íŒ¨ ì²´í¬
        if hasattr(response, 'error') and response.error:
            raise RuntimeError(f"Image upload failed: {response.error}")

        # Public URL ê°€ì ¸ì˜¤ê¸°
        public_url = supabase.storage.from_("thumbnails").get_public_url(file_path)

        return public_url

    except FileNotFoundError as e:
        raise RuntimeError(str(e))
    except Exception as e:
        raise RuntimeError(f"Image upload failed: {str(e)}")


def _handle_error(e: Exception) -> str:
    if isinstance(e, RuntimeError):
        return f"Error: {str(e)}"
    return f"Error: {type(e).__name__} - {str(e)}"


async def _call_openai_with_retry(prompt: str, max_tokens: int = 1000) -> str:
    _check_openai()

    for attempt in range(MAX_RETRIES):
        try:
            response = await openai_client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant for a technical archive platform."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            if attempt < MAX_RETRIES - 1:
                await asyncio.sleep(3 * (attempt + 1))
                continue
            else:
                raise e


# ============================================================================
# TOOLS
# ============================================================================

@mcp.tool(
    name="archive_search_archives",
    annotations={
        "title": "Search Archives",
        "readOnlyHint": True,
        "destructiveHint": False,
        "idempotentHint": True,
        "openWorldHint": True
    }
)
async def archive_search_archives(params: SearchArchivesInput) -> str:
    """
    Light Archive ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì•„ì¹´ì´ë¸Œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    í…Œì´ë¸”: archive_items
    ê²€ìƒ‰ ëŒ€ìƒ: title, description, content
    """
    try:
        _check_supabase()

        # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        query = supabase.table("archive_items").select("*")

        # ì¹´í…Œê³ ë¦¬ í•„í„°
        if params.category:
            query = query.eq("category", params.category.value)

        # Published ìƒíƒœë§Œ (ê¸°ë³¸)
        query = query.eq("status", "published")

        # í…ìŠ¤íŠ¸ ê²€ìƒ‰
        search_term = f"%{params.query}%"
        query = query.or_(f"title.ilike.{search_term},description.ilike.{search_term},content.ilike.{search_term}")

        # í˜ì´ì§€ë„¤ì´ì…˜ ë° ì •ë ¬
        query = query.range(params.offset, params.offset + params.limit - 1)
        query = query.order("created_at", desc=True)

        response = query.execute()
        archives = response.data

        if not archives:
            return f"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤: '{params.query}'"

        # Markdown í¬ë§·
        if params.response_format == ResponseFormat.MARKDOWN:
            lines = [f"# ê²€ìƒ‰ ê²°ê³¼: '{params.query}'", ""]
            lines.append(f"ì´ {len(archives)}ê°œ ê²°ê³¼")
            lines.append("")

            for i, archive in enumerate(archives, 1):
                lines.append(f"## {i}. {archive['title']}")
                lines.append(f"**ID**: `{archive['id']}`")
                lines.append(f"**ì¹´í…Œê³ ë¦¬**: {archive['category']}")
                if archive.get('sub_category'):
                    lines.append(f"**ë¶„ì•¼**: {archive['sub_category']}")
                if archive.get('description'):
                    lines.append(f"**ì„¤ëª…**: {archive['description']}")
                if archive.get('tags'):
                    tags_str = ", ".join([f"`{tag}`" for tag in archive['tags']])
                    lines.append(f"**íƒœê·¸**: {tags_str}")
                if archive.get('technologies'):
                    tech_str = ", ".join([f"`{tech}`" for tech in archive['technologies']])
                    lines.append(f"**ê¸°ìˆ **: {tech_str}")
                lines.append("")

            return "\n".join(lines)
        else:
            return json.dumps({"query": params.query, "archives": archives}, ensure_ascii=False, indent=2)

    except Exception as e:
        return _handle_error(e)


@mcp.tool(
    name="archive_get_archive",
    annotations={
        "title": "Get Archive Details",
        "readOnlyHint": True,
        "destructiveHint": False,
        "idempotentHint": True,
        "openWorldHint": True
    }
)
async def archive_get_archive(params: GetArchiveInput) -> str:
    """íŠ¹ì • ì•„ì¹´ì´ë¸Œì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        _check_supabase()

        response = supabase.table("archive_items").select("*").eq("id", params.archive_id).execute()

        if not response.data:
            return f"Error: Archive '{params.archive_id}' not found"

        archive = response.data[0]

        if params.response_format == ResponseFormat.MARKDOWN:
            lines = [f"# {archive['title']}", ""]
            lines.append(f"**ì¹´í…Œê³ ë¦¬**: {archive['category']}")
            if archive.get('sub_category'):
                lines.append(f"**ë¶„ì•¼**: {archive['sub_category']}")
            if archive.get('description'):
                lines.append(f"**ì„¤ëª…**: {archive['description']}")
            if archive.get('tags'):
                tags_str = ", ".join([f"`{tag}`" for tag in archive['tags']])
                lines.append(f"**íƒœê·¸**: {tags_str}")
            if archive.get('technologies'):
                tech_str = ", ".join([f"`{tech}`" for tech in archive['technologies']])
                lines.append(f"**ê¸°ìˆ **: {tech_str}")
            lines.append("")
            lines.append("---")
            lines.append("")
            if archive.get('content'):
                lines.append(archive['content'])

            return "\n".join(lines)
        else:
            return json.dumps(archive, ensure_ascii=False, indent=2, default=str)

    except Exception as e:
        return _handle_error(e)


@mcp.tool(
    name="archive_create_archive",
    annotations={
        "title": "Create Archive",
        "readOnlyHint": False,
        "destructiveHint": False,
        "idempotentHint": False,
        "openWorldHint": True
    }
)
async def archive_create_archive(params: CreateArchiveInput) -> str:
    """
    ìƒˆ ì•„ì¹´ì´ë¸Œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    **ìë™ ìƒì„± í•­ëª©:**
    - ID: timestamp-random í˜•ì‹ìœ¼ë¡œ ìë™ ìƒì„±
    - created_at: í˜„ì¬ ì‹œê°„ (ISO 8601)
    - updated_at: í˜„ì¬ ì‹œê°„ (ISO 8601)
    - published_at: í˜„ì¬ ì‹œê°„ (ISO 8601) - ìƒíƒœê°€ publishedì¸ ê²½ìš°
    - status: "draft" (ê¸°ë³¸ê°’)
    """
    try:
        _check_supabase()

        # ID ìë™ ìƒì„± (Next.js ì•±ê³¼ ë™ì¼í•œ íŒ¨í„´)
        archive_id = _generate_archive_id()

        # í˜„ì¬ ì‹œê°„ (ISO 8601 í˜•ì‹)
        now = datetime.utcnow().isoformat()

        archive_data = {
            "id": archive_id,
            "title": params.title,
            "content": params.content,
            "category": params.category.value,
            "description": params.description,
            "tags": params.tags,
            "technologies": params.technologies,
            "status": "draft",
            "view_count": 0,
            "comment_count": 0,
            "created_at": now,
            "updated_at": now,
            "published_at": now  # ë‚ ì§œ ìë™ ì„¤ì • (Next.js ì•±ê³¼ ë™ì¼)
        }

        # ì„ íƒì  í•„ë“œ
        if params.sub_category:
            archive_data["sub_category"] = params.sub_category
        if params.excerpt:
            archive_data["excerpt"] = params.excerpt
        if params.author:
            archive_data["author"] = params.author
        if params.difficulty:
            archive_data["difficulty"] = params.difficulty
        if params.thumbnail_url:
            archive_data["thumbnail_url"] = params.thumbnail_url

        response = supabase.table("archive_items").insert(archive_data).execute()

        if not response.data:
            return "Error: Failed to create archive"

        new_archive = response.data[0]

        # HTML êµ¬ì¡°í™”ëœ ì‘ë‹µ (4-5ì¤„ ê²°ë¡  ìš”ì•½ í¬í•¨)
        created_date = datetime.fromisoformat(new_archive['created_at'].replace('Z', '+00:00'))
        formatted_date = created_date.strftime('%Yë…„ %mì›” %dì¼ %H:%M')

        return f"""<h1>âœ… ì•„ì¹´ì´ë¸Œ ìƒì„± ì™„ë£Œ</h1>

<div style="background: #f5f5f5; padding: 16px; border-radius: 8px; margin: 16px 0;">
  <p><strong>ìš”ì•½:</strong> "{params.title}" ì•„ì¹´ì´ë¸Œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
  {params.category.value} ì¹´í…Œê³ ë¦¬ì˜ draft ìƒíƒœë¡œ ì €ì¥ë˜ì—ˆìœ¼ë©°,
  {len(params.tags)}ê°œì˜ íƒœê·¸ì™€ {len(params.technologies)}ê°œì˜ ê¸°ìˆ  ìŠ¤íƒì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.
  IDëŠ” {archive_id}ì´ë©°, {formatted_date}ì— ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
</div>

<h2>ìƒì„±ëœ ì•„ì¹´ì´ë¸Œ ì •ë³´</h2>

<table style="width: 100%; border-collapse: collapse; margin: 16px 0;">
  <tr style="border-bottom: 1px solid #ddd;">
    <td style="padding: 8px; font-weight: bold; width: 150px;">ID</td>
    <td style="padding: 8px;"><code>{new_archive['id']}</code></td>
  </tr>
  <tr style="border-bottom: 1px solid #ddd;">
    <td style="padding: 8px; font-weight: bold;">ì œëª©</td>
    <td style="padding: 8px;">{params.title}</td>
  </tr>
  <tr style="border-bottom: 1px solid #ddd;">
    <td style="padding: 8px; font-weight: bold;">ì¹´í…Œê³ ë¦¬</td>
    <td style="padding: 8px;">{params.category.value}</td>
  </tr>
  <tr style="border-bottom: 1px solid #ddd;">
    <td style="padding: 8px; font-weight: bold;">ìƒíƒœ</td>
    <td style="padding: 8px;">draft</td>
  </tr>
  <tr style="border-bottom: 1px solid #ddd;">
    <td style="padding: 8px; font-weight: bold;">ìƒì„±ì¼ì‹œ</td>
    <td style="padding: 8px;">{formatted_date}</td>
  </tr>
  <tr style="border-bottom: 1px solid #ddd;">
    <td style="padding: 8px; font-weight: bold;">íƒœê·¸</td>
    <td style="padding: 8px;">{', '.join(params.tags)}</td>
  </tr>
  <tr>
    <td style="padding: 8px; font-weight: bold;">ê¸°ìˆ  ìŠ¤íƒ</td>
    <td style="padding: 8px;">{', '.join(params.technologies)}</td>
  </tr>
</table>

<p style="color: #666; margin-top: 16px;">
  <strong>ë‹¤ìŒ ë‹¨ê³„:</strong>
  <a href="http://localhost:3000/admin/edit/{archive_id}">ê´€ë¦¬ì í˜ì´ì§€</a>ì—ì„œ
  ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì¶”ê°€ í¸ì§‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
</p>
"""

    except Exception as e:
        return _handle_error(e)


@mcp.tool(
    name="archive_update_archive",
    annotations={
        "title": "Update Archive",
        "readOnlyHint": False,
        "destructiveHint": False,
        "idempotentHint": False,
        "openWorldHint": True
    }
)
async def archive_update_archive(params: UpdateArchiveInput) -> str:
    """ì•„ì¹´ì´ë¸Œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤."""
    try:
        _check_supabase()

        update_data = {"updated_at": datetime.utcnow().isoformat()}

        if params.title:
            update_data["title"] = params.title
        if params.content:
            update_data["content"] = params.content
        if params.description:
            update_data["description"] = params.description
        if params.excerpt:
            update_data["excerpt"] = params.excerpt
        if params.category:
            update_data["category"] = params.category.value
        if params.sub_category:
            update_data["sub_category"] = params.sub_category
        if params.tags:
            update_data["tags"] = params.tags
        if params.technologies:
            update_data["technologies"] = params.technologies
        if params.difficulty:
            update_data["difficulty"] = params.difficulty

        if len(update_data) == 1:
            return "ë³€ê²½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

        supabase.table("archive_items").update(update_data).eq("id", params.archive_id).execute()

        return f"# âœ… ì•„ì¹´ì´ë¸Œ ìˆ˜ì • ì™„ë£Œ\n\n**ID**: `{params.archive_id}`"

    except Exception as e:
        return _handle_error(e)


# ============================================================================
# AI ë„êµ¬ ì œê±° - Claudeê°€ ì§ì ‘ ì‘ì„±í•˜ë¯€ë¡œ ë¶ˆí•„ìš”
# archive_generate_draft, archive_generate_summary, archive_suggest_tags
# ============================================================================

# @mcp.tool(
#     name="archive_generate_draft",
#     annotations={
#         "title": "Generate Draft (AI)",
#         "readOnlyHint": True,
#         "destructiveHint": False,
#         "idempotentHint": False,
#         "openWorldHint": True
#     }
# )
# async def archive_generate_draft(params: GenerateDraftInput) -> str:
#     """AIë¡œ ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤. (ì œê±°ë¨ - Claudeê°€ ì§ì ‘ ì‘ì„±)"""
#     pass


# @mcp.tool(
#     name="archive_generate_summary",
#     annotations={
#         "title": "Generate Summary (AI)",
#         "readOnlyHint": True,
#         "destructiveHint": False,
#         "idempotentHint": False,
#         "openWorldHint": True
#     }
# )
# async def archive_generate_summary(params: GenerateSummaryInput) -> str:
#     """AIë¡œ ìš”ì•½ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤. (ì œê±°ë¨ - Claudeê°€ ì§ì ‘ ì‘ì„±)"""
#     pass


# @mcp.tool(
#     name="archive_suggest_tags",
#     annotations={
#         "title": "Suggest Tags (AI)",
#         "readOnlyHint": True,
#         "destructiveHint": False,
#         "idempotentHint": False,
#         "openWorldHint": True
#     }
# )
# async def archive_suggest_tags(params: SuggestTagsInput) -> str:
#     """AIë¡œ íƒœê·¸ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. (ì œê±°ë¨ - Claudeê°€ ì§ì ‘ ì‘ì„±)"""
#     pass


@mcp.tool(
    name="archive_find_related",
    annotations={
        "title": "Find Related Archives",
        "readOnlyHint": True,
        "destructiveHint": False,
        "idempotentHint": True,
        "openWorldHint": True
    }
)
async def archive_find_related(params: FindRelatedInput) -> str:
    """ìœ ì‚¬ ì•„ì¹´ì´ë¸Œë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        _check_supabase()

        # ê¸°ì¤€ ì•„ì¹´ì´ë¸Œ ì¡°íšŒ
        base_response = supabase.table("archive_items").select("*").eq("id", params.archive_id).execute()
        if not base_response.data:
            return f"Error: Archive '{params.archive_id}' not found"

        base_archive = base_response.data[0]
        base_tags = set(base_archive.get('tags', []))
        base_tech = set(base_archive.get('technologies', []))

        # ëª¨ë“  published ì•„ì¹´ì´ë¸Œ ì¡°íšŒ
        all_response = supabase.table("archive_items").select("*").eq("status", "published").neq("id", params.archive_id).execute()
        all_archives = all_response.data

        # ìœ ì‚¬ë„ ê³„ì‚°
        scored = []
        for archive in all_archives:
            score = 0

            if archive['category'] == base_archive['category']:
                score += 30

            archive_tags = set(archive.get('tags', []))
            archive_tech = set(archive.get('technologies', []))

            tag_matches = len(base_tags & archive_tags)
            score += tag_matches * 10

            tech_matches = len(base_tech & archive_tech)
            score += tech_matches * 5

            if score > 0:
                scored.append({"archive": archive, "score": score})

        scored.sort(key=lambda x: x['score'], reverse=True)
        related = scored[:params.limit]

        if not related:
            return f"'{base_archive['title']}'ì™€ ìœ ì‚¬í•œ ì•„ì¹´ì´ë¸Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        if params.response_format == ResponseFormat.MARKDOWN:
            lines = [f"# ğŸ” '{base_archive['title']}'ì™€ ê´€ë ¨ëœ ì•„ì¹´ì´ë¸Œ", ""]
            lines.append(f"ì´ {len(related)}ê°œ ë°œê²¬")
            lines.append("")

            for i, item in enumerate(related, 1):
                archive = item['archive']
                lines.append(f"## {i}. {archive['title']} (ìœ ì‚¬ë„: {item['score']}ì )")
                lines.append(f"**ID**: `{archive['id']}`")
                lines.append(f"**ì¹´í…Œê³ ë¦¬**: {archive['category']}")
                if archive.get('tags'):
                    lines.append(f"**íƒœê·¸**: {', '.join([f'`{t}`' for t in archive['tags']])}")
                lines.append("")

            return "\n".join(lines)
        else:
            return json.dumps({"base_archive": base_archive, "related": related}, ensure_ascii=False, indent=2, default=str)

    except Exception as e:
        return _handle_error(e)


@mcp.tool(
    name="archive_list_archives",
    annotations={
        "title": "List Archives",
        "readOnlyHint": True,
        "destructiveHint": False,
        "idempotentHint": True,
        "openWorldHint": True
    }
)
async def archive_list_archives(params: ListArchivesInput) -> str:
    """ì•„ì¹´ì´ë¸Œ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        _check_supabase()

        query = supabase.table("archive_items").select("*")

        if params.category:
            query = query.eq("category", params.category.value)
        if params.status:
            query = query.eq("status", params.status.value)

        query = query.range(params.offset, params.offset + params.limit - 1)
        query = query.order("created_at", desc=True)

        response = query.execute()
        archives = response.data

        if params.response_format == ResponseFormat.MARKDOWN:
            lines = ["# ğŸ“š ì•„ì¹´ì´ë¸Œ ëª©ë¡", ""]
            lines.append(f"ì´ {len(archives)}ê°œ")
            lines.append("")

            for i, archive in enumerate(archives, 1):
                lines.append(f"## {i}. {archive['title']}")
                lines.append(f"**ID**: `{archive['id']}`")
                lines.append(f"**ì¹´í…Œê³ ë¦¬**: {archive['category']}")
                if archive.get('tags'):
                    lines.append(f"**íƒœê·¸**: {', '.join([f'`{t}`' for t in archive['tags']])}")
                lines.append("")

            return "\n".join(lines)
        else:
            return json.dumps({"archives": archives}, ensure_ascii=False, indent=2, default=str)

    except Exception as e:
        return _handle_error(e)


# ============================================================================
# ì´ë¯¸ì§€ ì—…ë¡œë“œ ë„êµ¬ - ë¹„í™œì„±í™” (íŒŒì¼ ì‹œìŠ¤í…œ ì ‘ê·¼ ì œí•œìœ¼ë¡œ ì‘ë™ ì•ˆ í•¨)
# ëŒ€ì‹  Next.js ì•±ì—ì„œ ì§ì ‘ ì—…ë¡œë“œí•˜ì„¸ìš”: achive.lightsoft.dev   
# ============================================================================

# @mcp.tool(
#     name="archive_upload_image",
#     annotations={
#         "title": "Upload Image to Supabase Storage (DISABLED)",
#         "readOnlyHint": False,
#         "destructiveHint": False,
#         "idempotentHint": False,
#         "openWorldHint": True
#     }
# )
# async def archive_upload_image(params: UploadImageInput) -> str:
#     """
#     DISABLED: MCP cannot access file system paths.
#     Please use Next.js app to upload images: achive.lightsoft.dev 
#     """
#     return """# âš ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ ë„êµ¬ ë¹„í™œì„±í™”
#
# MCP ì„œë²„ê°€ íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
#
# **í•´ê²° ë°©ë²•:**
# 1. achive.lightsoft.dev ì ‘ì†
# 2. ìƒˆ ì•„ì¹´ì´ë¸Œ ìƒì„± ë˜ëŠ” ê¸°ì¡´ ì•„ì¹´ì´ë¸Œ ìˆ˜ì •
# 3. ì´ë¯¸ì§€ ì—…ë¡œë“œ ê¸°ëŠ¥ ì‚¬ìš©
# 4. ì—…ë¡œë“œëœ URLì„ ë³¸ë¬¸ì— ì‚¬ìš©
# """


# @mcp.tool(
#     name="archive_analyze_image",
#     annotations={
#         "title": "Analyze Image with AI (DISABLED)",
#         "readOnlyHint": True,
#         "destructiveHint": False,
#         "idempotentHint": False,
#         "openWorldHint": True
#     }
# )
# async def archive_analyze_image(params: AnalyzeImageInput) -> str:
#     """
#     DISABLED: MCP cannot access file system paths.
#     """
#     return """# âš ï¸ ì´ë¯¸ì§€ ë¶„ì„ ë„êµ¬ ë¹„í™œì„±í™”
#
# MCP ì„œë²„ê°€ íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
# Claudeê°€ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë¶„ì„í•  ìˆ˜ ìˆìœ¼ë‹ˆ, ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•´ì£¼ì‹œë©´ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤.
# """


# @mcp.tool(
#     name="archive_generate_draft_with_images",
#     annotations={
#         "title": "Generate Draft with Images (DISABLED)",
#         "readOnlyHint": False,
#         "destructiveHint": False,
#         "idempotentHint": False,
#         "openWorldHint": True
#     }
# )
# async def archive_generate_draft_with_images(params: GenerateDraftWithImagesInput) -> str:
#     """
#     DISABLED: MCP cannot access file system paths.
#     """
#     return """# âš ï¸ ì´ë¯¸ì§€ ê¸°ë°˜ ì´ˆì•ˆ ìƒì„± ë„êµ¬ ë¹„í™œì„±í™”
#
# MCP ì„œë²„ê°€ íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
#
# **í•´ê²° ë°©ë²•:**
# 1. ì´ë¯¸ì§€ë¥¼ Claudeì—ê²Œ ì§ì ‘ ì²¨ë¶€
# 2. "ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì„œ ì•„ì¹´ì´ë¸Œ ì´ˆì•ˆ ì‘ì„±í•´ì¤˜"ë¼ê³  ìš”ì²­
# 3. ìƒì„±ëœ ì´ˆì•ˆìœ¼ë¡œ `archive_create_archive` ë„êµ¬ ì‚¬ìš©
# 4. achive.lightsoft.devì—ì„œ ì´ë¯¸ì§€ ì—…ë¡œë“œ
# """


# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    mcp.run()
